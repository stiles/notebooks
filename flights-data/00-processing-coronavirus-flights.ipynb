{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing world flights data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import geojson\n",
    "import json\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "import pyarrow\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, read our data from Flightradar24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/mhustiles/data/github/notebooks/flights-data/coronavirus/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  urls = 'https://secure.flightradar24.com/general_media/',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in urls: \n",
    "#     !wget --user general_media --password OpE0SimNCt -r -np -nH --cut-dirs=3 -R index.html '{u}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip \\*.zip\n",
    "# !rm -f *.zip\n",
    "# !rm -f *.tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir positions\n",
    "# !mkdir flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv -f *flights.csv flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv -f *.csv positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 'positions' data showing each point along a flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path for positions and define the files we'll concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>altitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>radar_id</th>\n",
       "      <th>speed</th>\n",
       "      <th>squawk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1546302500</td>\n",
       "      <td>682</td>\n",
       "      <td>351</td>\n",
       "      <td>33.82970</td>\n",
       "      <td>-118.15107</td>\n",
       "      <td>8444</td>\n",
       "      <td>96</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1546302513</td>\n",
       "      <td>799</td>\n",
       "      <td>354</td>\n",
       "      <td>33.83565</td>\n",
       "      <td>-118.15157</td>\n",
       "      <td>8444</td>\n",
       "      <td>97</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1546302537</td>\n",
       "      <td>875</td>\n",
       "      <td>74</td>\n",
       "      <td>33.84734</td>\n",
       "      <td>-118.15132</td>\n",
       "      <td>8444</td>\n",
       "      <td>101</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1546302545</td>\n",
       "      <td>899</td>\n",
       "      <td>19</td>\n",
       "      <td>33.85181</td>\n",
       "      <td>-118.15102</td>\n",
       "      <td>8444</td>\n",
       "      <td>104</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1546302552</td>\n",
       "      <td>800</td>\n",
       "      <td>7</td>\n",
       "      <td>33.85536</td>\n",
       "      <td>-118.15085</td>\n",
       "      <td>8444</td>\n",
       "      <td>106</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_id  altitude  heading  latitude  longitude  radar_id  speed  \\\n",
       "0   1546302500       682      351  33.82970 -118.15107      8444     96   \n",
       "1   1546302513       799      354  33.83565 -118.15157      8444     97   \n",
       "2   1546302537       875       74  33.84734 -118.15132      8444    101   \n",
       "3   1546302545       899       19  33.85181 -118.15102      8444    104   \n",
       "4   1546302552       800        7  33.85536 -118.15085      8444    106   \n",
       "\n",
       "   squawk  \n",
       "0    1206  \n",
       "1    1206  \n",
       "2    1206  \n",
       "3    1206  \n",
       "4    1206  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_position = pd.read_csv('positions/20190101_520786143.csv')\n",
    "a_position.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'positions'\n",
    "files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv and create a 'flightid' field so we can track unique flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = (pd.read_csv(f, encoding = \"ISO-8859-1\", low_memory=False)\\\n",
    "           .assign(flightid=os.path.basename(f)) for f in files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concateate the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>altitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>radar_id</th>\n",
       "      <th>speed</th>\n",
       "      <th>squawk</th>\n",
       "      <th>flightid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1548698910</td>\n",
       "      <td>500</td>\n",
       "      <td>310</td>\n",
       "      <td>33.97671</td>\n",
       "      <td>-118.26622</td>\n",
       "      <td>26826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190128_525530318.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1571361703</td>\n",
       "      <td>575</td>\n",
       "      <td>237</td>\n",
       "      <td>34.05377</td>\n",
       "      <td>-118.23032</td>\n",
       "      <td>3021</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1571361709</td>\n",
       "      <td>675</td>\n",
       "      <td>268</td>\n",
       "      <td>34.05359</td>\n",
       "      <td>-118.23167</td>\n",
       "      <td>3021</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1571361729</td>\n",
       "      <td>875</td>\n",
       "      <td>299</td>\n",
       "      <td>34.05492</td>\n",
       "      <td>-118.23851</td>\n",
       "      <td>3021</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1571361735</td>\n",
       "      <td>900</td>\n",
       "      <td>306</td>\n",
       "      <td>34.05597</td>\n",
       "      <td>-118.24036</td>\n",
       "      <td>3021</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_id  altitude  heading  latitude  longitude  radar_id  speed  \\\n",
       "0   1548698910       500      310  33.97671 -118.26622     26826      0   \n",
       "1   1571361703       575      237  34.05377 -118.23032      3021     36   \n",
       "2   1571361709       675      268  34.05359 -118.23167      3021     46   \n",
       "3   1571361729       875      299  34.05492 -118.23851      3021     67   \n",
       "4   1571361735       900      306  34.05597 -118.24036      3021     65   \n",
       "\n",
       "   squawk                flightid  \n",
       "0       0  20190128_525530318.csv  \n",
       "1       0  20191018_579082629.csv  \n",
       "2       0  20191018_579082629.csv  \n",
       "3       0  20191018_579082629.csv  \n",
       "4       0  20191018_579082629.csv  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_df = pd.concat(file_df, ignore_index=True)\n",
    "positions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5871403"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined our newly processed flight positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df['flightid'] = positions_df['flightid']\\\n",
    "    .str.replace('.csv','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the flightid field so we have a date string to convert later and also a flightid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df[['datestr','flight_id']] = positions_df.flightid.str.split(\"_\",expand=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>altitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>radar_id</th>\n",
       "      <th>speed</th>\n",
       "      <th>squawk</th>\n",
       "      <th>flightid</th>\n",
       "      <th>datestr</th>\n",
       "      <th>flight_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1548698910</td>\n",
       "      <td>500</td>\n",
       "      <td>310</td>\n",
       "      <td>33.97671</td>\n",
       "      <td>-118.26622</td>\n",
       "      <td>26826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190128_525530318</td>\n",
       "      <td>20190128</td>\n",
       "      <td>525530318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1571361703</td>\n",
       "      <td>575</td>\n",
       "      <td>237</td>\n",
       "      <td>34.05377</td>\n",
       "      <td>-118.23032</td>\n",
       "      <td>3021</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629</td>\n",
       "      <td>20191018</td>\n",
       "      <td>579082629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1571361709</td>\n",
       "      <td>675</td>\n",
       "      <td>268</td>\n",
       "      <td>34.05359</td>\n",
       "      <td>-118.23167</td>\n",
       "      <td>3021</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629</td>\n",
       "      <td>20191018</td>\n",
       "      <td>579082629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1571361729</td>\n",
       "      <td>875</td>\n",
       "      <td>299</td>\n",
       "      <td>34.05492</td>\n",
       "      <td>-118.23851</td>\n",
       "      <td>3021</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629</td>\n",
       "      <td>20191018</td>\n",
       "      <td>579082629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1571361735</td>\n",
       "      <td>900</td>\n",
       "      <td>306</td>\n",
       "      <td>34.05597</td>\n",
       "      <td>-118.24036</td>\n",
       "      <td>3021</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>20191018_579082629</td>\n",
       "      <td>20191018</td>\n",
       "      <td>579082629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_id  altitude  heading  latitude  longitude  radar_id  speed  \\\n",
       "0   1548698910       500      310  33.97671 -118.26622     26826      0   \n",
       "1   1571361703       575      237  34.05377 -118.23032      3021     36   \n",
       "2   1571361709       675      268  34.05359 -118.23167      3021     46   \n",
       "3   1571361729       875      299  34.05492 -118.23851      3021     67   \n",
       "4   1571361735       900      306  34.05597 -118.24036      3021     65   \n",
       "\n",
       "   squawk            flightid   datestr  flight_id  \n",
       "0       0  20190128_525530318  20190128  525530318  \n",
       "1       0  20191018_579082629  20191018  579082629  \n",
       "2       0  20191018_579082629  20191018  579082629  \n",
       "3       0  20191018_579082629  20191018  579082629  \n",
       "4       0  20191018_579082629  20191018  579082629  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the 'datestr' field into something we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df['date'] = pd.to_datetime(positions_df.datestr, format='%Y%m%d')\n",
    "positions_df['month'] = positions_df['date'].dt.month \n",
    "positions_df['day'] = positions_df['date'].dt.day \n",
    "positions_df['weekday'] = positions_df['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the unix timestampt to human datetime and localize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df['date_time'] = pd.to_datetime(positions_df['snapshot_id'],unit='s')\n",
    "positions_df['utc_datetime'] = \\\n",
    "    pd.to_datetime(positions_df['date_time'], format='%Y-%m-%dT%H:%M:%SZ').dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df['datetime_pst'] = positions_df['utc_datetime'].dt.tz_convert('America/Los_Angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df['date'] = pd.to_datetime(positions_df['datetime_pst']).dt.strftime('%m/%d/%Y')\n",
    "positions_df['time'] = pd.to_datetime(positions_df['datetime_pst']).dt.strftime('%H:%M:%S')\n",
    "positions_df['display_time'] = pd.to_datetime(positions_df['datetime_pst']).dt.strftime('%I:%M %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df = \\\n",
    "    positions_df.drop(['snapshot_id', 'radar_id', 'day',\\\n",
    "                          'datestr','utc_datetime','date_time', 'datetime_pst', 'display_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.DataFrame(positions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions.sort_values(by='date', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 'flights' metadata about each set of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path for flights and define the files we'll concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'flights/20191215_flights.csv' does not exist: b'flights/20191215_flights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-51fa14081c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma_flight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flights/20191215_flights.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'flights/20191215_flights.csv' does not exist: b'flights/20191215_flights.csv'"
     ]
    }
   ],
   "source": [
    "a_flight = pd.read_csv('flights/20191215_flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'flights'\n",
    "files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv and create a 'date' field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = (pd.read_csv(f, encoding = \"ISO-8859-1\", low_memory=False)\\\n",
    "           .assign(date=os.path.basename(f)) for f in files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined our newly processed flight files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = pd.concat(file_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up our dates for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df['date'] = flights_df['date']\\\n",
    "    .str.replace('_flights.csv','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df['date'] = pd.to_datetime(flights_df.date, format='%Y%m%d')\n",
    "flights_df['month'] = flights_df['date'].dt.month \n",
    "flights_df['day'] = flights_df['date'].dt.day \n",
    "flights_df['weekday'] = flights_df['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataframe with flights and export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.DataFrame(flights_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flights.to_csv('../output/all_flights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by flight ID to associate each flight with an aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_id_grouped = flights.groupby(['flight_id', 'reg']).agg('size').reset_index(name='count')\n",
    "flight_id_grouped = \\\n",
    "    flight_id_grouped.drop(['count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flight_id_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge to add aircraft ID and registration N number to each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_id_grouped['flight_id'] = flight_id_grouped['flight_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = positions.merge(flight_id_grouped, on='flight_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = gpd.GeoDataFrame(positions.merge(src, left_on='reg', right_on='n_number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# positions.reset_index().to_feather('/Users/mhustiles/data/data/helicopters/all_positions.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to positions to a GeoDataFrame using lon/lat for each point in the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions.loc[112000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_geo = gpd.GeoDataFrame(positions, \\\n",
    "                geometry=gpd.points_from_xy(positions['longitude'], positions['latitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_geo.crs = \"epsg:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop though all the aircraft, creating frames for each set of positions to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numbers = positions_geo.groupby(['reg']).agg('size').reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choppers_list = n_numbers['reg'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_numbers = []\n",
    "for n in choppers_list:\n",
    "    n_numbers.append(dict(n_number = n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "\n",
    "# for l in n_numbers:\n",
    "#     n = l['n_number']\n",
    "#     aircraft = positions_geo[positions_geo['n_number'] == n]\n",
    "#     aircraft.to_file(f'/Users/mhustiles/data/data/helicopters/' + n + '.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tippecanoe --generate-ids --force -Z8 -z11 -r1 -pk -pf -o \\\n",
    "/Users/mhustiles/data/data/helicopters/N661PD.mbtiles \\\n",
    "/Users/mhustiles/data/data/helicopters/N661PD.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the flight positions inside half-mile hexagons over LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbins = gpd.read_file('/Users/mhustiles/data/github/notebooks/flights-data/input/halfmile.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hexbins.crs = \"epsg:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export LAPD flights aggregated into hexbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_aircraft = positions_geo.groupby(['reg']).agg('size').reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_choppers_list = la_aircraft['reg'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_choppers = []\n",
    "\n",
    "for c in la_choppers_list:\n",
    "    la_choppers.append(dict(n_number = c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_la = pd.DataFrame()\n",
    "\n",
    "# for n in la_choppers:\n",
    "#     c = n['n_number']\n",
    "#     choppers = positions_geo[positions_geo['reg'] == c]\n",
    "#     choppers.crs = \"epsg:4326\"\n",
    "#     dfsjoin = gpd.sjoin(hexbins,choppers)\n",
    "#     dfpivot = pd.pivot_table(dfsjoin,index='id',columns='n_number',aggfunc={'n_number':len})\n",
    "#     dfpivot.columns = dfpivot.columns.droplevel()\n",
    "#     dfpolynew = hexbins.merge(dfpivot, how='left',on='id')\n",
    "#     dfpolynew.to_file('/Users/mhustiles/data/data/helicopters/' + c + 'hex.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palisades = positions_geo[(positions_geo['date'] == '10/21/2019')\\\n",
    "                         & ((positions_geo['owner'] == 'LA County Fire') |\n",
    "                           (positions_geo['owner'] == 'LA Fire'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palisades.to_file('/Users/mhustiles/data/data/helicopters/palisades.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty = positions_geo[(positions_geo['date'] == '10/28/2019')\\\n",
    "                         & ((positions_geo['owner'] == 'LA Fire'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty.to_file('/Users/mhustiles/data/data/helicopters/getty.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tippecanoe --generate-ids --force -Z8 -z11 -r1 -pk -pf -o \\\n",
    "/Users/mhustiles/data/data/helicopters/palisades.mbtiles \\\n",
    "/Users/mhustiles/data/data/helicopters/palisades.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need flight paths. Convert to points to linestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty.loc[3915167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty_line = getty.groupby(['flight_id', 'n_number'])['geometry']\\\n",
    "    .apply(lambda x: LineString(x.tolist()) if x.size > 1 else x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty_line_geo = gpd.GeoDataFrame(getty_line, geometry='geometry').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty_line_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getty_line_geo.to_file('/Users/mhustiles/data/data/helicopters/getty_line_geo.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tippecanoe --generate-ids --force -Z8 -z11 -r1 -pk -pf -o \\\n",
    "/Users/mhustiles/data/data/helicopters/getty_line_geo.mbtiles \\\n",
    "/Users/mhustiles/data/data/helicopters/getty_line_geo.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in FAA registration records and merge with each aircraft in our fligts, positions frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration = pd.read_csv('/Users/mhustiles/data/github/notebooks/aircraft/output/la_cops_choppers_slim.csv')\n",
    "registration.rename(columns={\"Unnamed: 0\": \"id\", 'n_number':'reg'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration['reg'] = ('n' + registration['reg']).str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the owner names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration['name'] = registration['name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapd = [['LAPD AIR SUPPORT DIVISION', 'LOS ANGELES POLICE DEPT AIR SUPPORT DIVISION']]\n",
    "lapd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agency_names (row):\n",
    "   if row['name'] == 'LAPD AIR SUPPORT DIVISION':\n",
    "      return 'LAPD'\n",
    "   if row['name'] == 'LOS ANGELES POLICE DEPT AIR SUPPORT DIVISION' :\n",
    "      return 'LAPD'\n",
    "   return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration['agency'] = registration.apply (lambda row: agency_names(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_reg = positions_geo.merge(registration, on='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_lapd = positions_reg[positions_reg['agency'] == 'LAPD']\n",
    "len(positions_lapd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positions_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_lapd.to_file('/Users/mhustiles/data/data/helicopters/positions_lapd.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
